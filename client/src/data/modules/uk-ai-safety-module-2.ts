import type { QuizQuestion } from '@/types/quiz';

export const ukAiSafetyModule2Quiz: QuizQuestion[] = [
  {
    id: 1,
    question: 'What is the primary mission of the UK AI Safety Institute?',
    options: ['Regulating AI companies', 'Advancing AI safety science and evaluation', 'Developing commercial AI products', 'Licensing AI developers'],
    correctAnswer: 1,
    explanation: 'The UK AI Safety Institute\'s primary mission is to advance AI safety science, develop evaluation methodologies, and assess frontier AI models for potential risks.'
  },
  {
    id: 2,
    question: 'Which type of AI models does the AI Safety Institute primarily focus on evaluating?',
    options: ['All AI models equally', 'Frontier and foundation models', 'Only chatbots', 'Only image generators'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute focuses primarily on frontier and foundation models - the most capable AI systems that could pose significant risks.'
  },
  {
    id: 3,
    question: 'What is "red teaming" in the context of AI safety?',
    options: ['A marketing strategy', 'Adversarial testing to find vulnerabilities', 'A team of developers', 'A regulatory compliance process'],
    correctAnswer: 1,
    explanation: 'Red teaming involves adversarial testing where experts attempt to find vulnerabilities, biases, or harmful capabilities in AI systems.'
  },
  {
    id: 4,
    question: 'How does the AI Safety Institute collaborate internationally?',
    options: ['It operates in isolation', 'Through partnerships with other national AI safety institutes', 'Only through the United Nations', 'It does not collaborate internationally'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute collaborates with international partners including the US AI Safety Institute and other national bodies.'
  },
  {
    id: 5,
    question: 'What is the AI Safety Institute\'s approach to transparency?',
    options: ['Complete secrecy', 'Publishing research and evaluation methodologies openly', 'Only sharing with government', 'Selling reports to companies'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute publishes research findings and evaluation methodologies openly to advance the field of AI safety.'
  },
  {
    id: 6,
    question: 'What capability assessments does the AI Safety Institute conduct?',
    options: ['Only speed tests', 'Evaluations of dangerous capabilities like bioweapons knowledge', 'Only user interface testing', 'Marketing effectiveness'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute conducts capability assessments including evaluations of potentially dangerous capabilities.'
  },
  {
    id: 7,
    question: 'How does the AI Safety Institute engage with AI developers?',
    options: ['Through mandatory inspections only', 'Voluntary partnerships and pre-deployment testing agreements', 'Legal enforcement actions', 'It does not engage with developers'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute engages with AI developers through voluntary partnerships and agreements to conduct pre-deployment safety testing.'
  },
  {
    id: 8,
    question: 'What role does the AI Safety Institute play in policy development?',
    options: ['None', 'Providing technical expertise to inform government policy', 'Making all AI policy decisions', 'Only implementing existing policies'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute provides technical expertise and research findings to inform government AI policy decisions.'
  },
  {
    id: 9,
    question: 'What is the AI Safety Institute\'s stance on open-source AI?',
    options: ['Completely against it', 'Recognizes both benefits and risks that need assessment', 'Only supports open-source', 'Has no position'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute recognizes that open-source AI has both benefits and risks that require careful assessment.'
  },
  {
    id: 10,
    question: 'How does the AI Safety Institute measure AI safety progress?',
    options: ['Only through financial metrics', 'Through benchmarks, evaluations, and ongoing research', 'By counting regulations', 'It does not measure progress'],
    correctAnswer: 1,
    explanation: 'The AI Safety Institute measures progress through developing and applying safety benchmarks and conducting evaluations.'
  }
];
