import type { QuizQuestion } from '@/types/quiz';

export const australiaAiEthicsModule3Quiz: QuizQuestion[] = [
  {
    id: 1,
    question: 'What does the "transparency and explainability" principle require in Australia\'s AI Ethics Framework?',
    options: [
      'AI systems must be open source',
      'There should be transparency about when AI is being used and explanations of how it works',
      'Only technical experts need to understand AI',
      'Transparency is optional',
    ],
    correctAnswer: 1,
    explanation: 'The transparency and explainability principle requires that there be transparency and responsible disclosure about when AI is being used, and that AI systems provide explanations that people can understand.',
  },
  {
    id: 2,
    question: 'When must individuals be informed that AI is being used under Australian guidelines?',
    options: [
      'Never',
      'Only after decisions are made',
      'When AI is used to make decisions that significantly affect them',
      'Only for government AI',
    ],
    correctAnswer: 2,
    explanation: 'Australian guidelines require that individuals be informed when AI is being used to make decisions that significantly affect them, enabling them to understand and potentially contest those decisions.',
  },
  {
    id: 3,
    question: 'What level of explanation should AI systems provide under Australian AI ethics?',
    options: [
      'Highly technical explanations only',
      'Explanations appropriate to the audience and context',
      'No explanations are required',
      'Only written explanations',
    ],
    correctAnswer: 1,
    explanation: 'AI systems should provide explanations that are appropriate to the audience and context, ensuring that affected individuals can understand how decisions were made.',
  },
  {
    id: 4,
    question: 'How does Australia\'s framework address "black box" AI systems?',
    options: [
      'Black box systems are prohibited',
      'Black box systems are acceptable without restrictions',
      'Additional measures may be needed to ensure accountability when explainability is limited',
      'Only government can use black box systems',
    ],
    correctAnswer: 2,
    explanation: 'When AI systems have limited explainability (black box), additional measures may be needed to ensure accountability, such as enhanced testing, monitoring, and human oversight.',
  },
  {
    id: 5,
    question: 'What information should be disclosed about AI system capabilities and limitations?',
    options: [
      'Only capabilities should be disclosed',
      'Both capabilities and limitations should be clearly communicated',
      'Limitations should be hidden',
      'Only technical specifications',
    ],
    correctAnswer: 1,
    explanation: 'Organizations should clearly communicate both the capabilities and limitations of their AI systems, enabling users to make informed decisions about reliance on AI outputs.',
  },
  {
    id: 6,
    question: 'How should organizations communicate AI-related risks to users?',
    options: [
      'Risks should not be communicated',
      'Clear, accessible communication of relevant risks',
      'Only in legal disclaimers',
      'Only to business users',
    ],
    correctAnswer: 1,
    explanation: 'Organizations should provide clear, accessible communication of relevant AI-related risks to users, enabling informed decision-making and appropriate caution.',
  },
  {
    id: 7,
    question: 'What is the role of documentation in supporting AI transparency?',
    options: [
      'Documentation is not related to transparency',
      'Documentation supports transparency by recording system design, decisions, and rationales',
      'Only external documentation matters',
      'Documentation is only for developers',
    ],
    correctAnswer: 1,
    explanation: 'Documentation plays a crucial role in supporting AI transparency by recording system design decisions, rationales, and changes, enabling accountability and review.',
  },
  {
    id: 8,
    question: 'How does Australia\'s framework address AI system auditing for transparency?',
    options: [
      'Auditing is not required',
      'Auditing can verify transparency claims and identify gaps',
      'Only government AI needs auditing',
      'Auditing is only for financial aspects',
    ],
    correctAnswer: 1,
    explanation: 'Auditing can play an important role in verifying transparency claims, identifying gaps in disclosure, and ensuring organizations meet their transparency obligations.',
  },
  {
    id: 9,
    question: 'What is the relationship between transparency and trust in AI under Australian guidelines?',
    options: [
      'No relationship',
      'Transparency builds trust by enabling understanding and accountability',
      'Trust is more important than transparency',
      'Transparency reduces trust',
    ],
    correctAnswer: 1,
    explanation: 'Australian guidelines recognize that transparency builds trust in AI systems by enabling users and stakeholders to understand how systems work and hold organizations accountable.',
  },
  {
    id: 10,
    question: 'How should organizations balance transparency with protecting intellectual property?',
    options: [
      'IP always takes precedence',
      'Transparency always takes precedence',
      'Balance both through appropriate disclosure that protects IP while meeting transparency needs',
      'No balance is needed',
    ],
    correctAnswer: 2,
    explanation: 'Organizations should balance transparency with IP protection through appropriate disclosure mechanisms that meet transparency needs while protecting legitimate intellectual property interests.',
  },
];
