import type { QuizQuestion } from '@/types/quiz';

export const australiaAiEthicsModule2Quiz: QuizQuestion[] = [
  {
    id: 1,
    question: 'What does the "reliability and safety" principle require in Australia\'s AI Ethics Framework?',
    options: [
      'AI systems must be 100% accurate',
      'AI systems should operate reliably and safely throughout their lifecycle',
      'AI systems should never fail',
      'Only government AI needs to be reliable',
    ],
    correctAnswer: 1,
    explanation: 'The reliability and safety principle requires that AI systems operate reliably and safely throughout their lifecycle, with appropriate safeguards to prevent harm.',
  },
  {
    id: 2,
    question: 'How should organizations assess AI system risks under Australian guidelines?',
    options: [
      'Only assess financial risks',
      'Comprehensive assessment of potential harms to individuals and society',
      'Risk assessment is optional',
      'Only assess technical risks',
    ],
    correctAnswer: 1,
    explanation: 'Organizations should conduct comprehensive risk assessments that consider potential harms to individuals, communities, and society, not just technical or financial risks.',
  },
  {
    id: 3,
    question: 'What is the purpose of AI system testing under Australian AI ethics guidelines?',
    options: [
      'Only to verify functionality',
      'To ensure systems meet ethical requirements and identify potential harms',
      'Testing is not required',
      'Only to meet marketing claims',
    ],
    correctAnswer: 1,
    explanation: 'AI system testing under Australian guidelines should ensure systems meet ethical requirements, identify potential harms, and verify that safeguards are effective.',
  },
  {
    id: 4,
    question: 'How does Australia\'s framework address AI system failures?',
    options: [
      'Failures are acceptable if rare',
      'Organizations must have processes to identify, report, and address failures',
      'Failures are only relevant for safety-critical systems',
      'No guidance on failures',
    ],
    correctAnswer: 1,
    explanation: 'Australia\'s framework requires organizations to have processes in place to identify, report, and address AI system failures, including mechanisms for continuous improvement.',
  },
  {
    id: 5,
    question: 'What role does monitoring play in AI system safety under Australian guidelines?',
    options: [
      'Monitoring is optional',
      'Continuous monitoring to detect issues and ensure ongoing safety',
      'Only initial monitoring is required',
      'Monitoring is only for high-risk systems',
    ],
    correctAnswer: 1,
    explanation: 'Continuous monitoring is essential under Australian guidelines to detect emerging issues, ensure ongoing safety, and enable timely intervention when problems arise.',
  },
  {
    id: 6,
    question: 'How should organizations handle AI system updates under Australian AI ethics principles?',
    options: [
      'Updates don\'t require ethical review',
      'Updates should be assessed for ethical implications and potential new risks',
      'Only major updates need review',
      'Updates are the vendor\'s responsibility',
    ],
    correctAnswer: 1,
    explanation: 'Organizations should assess AI system updates for ethical implications and potential new risks, ensuring that updates don\'t introduce new harms or undermine existing safeguards.',
  },
  {
    id: 7,
    question: 'What is the recommended approach to AI system documentation in Australia?',
    options: [
      'Documentation is optional',
      'Comprehensive documentation of design, testing, risks, and safeguards',
      'Only technical documentation is needed',
      'Documentation is only for regulators',
    ],
    correctAnswer: 1,
    explanation: 'Comprehensive documentation is recommended, covering system design, testing procedures, identified risks, implemented safeguards, and ongoing monitoring results.',
  },
  {
    id: 8,
    question: 'How does Australia\'s framework address AI systems in safety-critical applications?',
    options: [
      'No special requirements',
      'Enhanced scrutiny, testing, and safeguards for safety-critical applications',
      'Safety-critical AI is banned',
      'Same requirements as all AI systems',
    ],
    correctAnswer: 1,
    explanation: 'Australia\'s framework recognizes that AI systems in safety-critical applications require enhanced scrutiny, more rigorous testing, and stronger safeguards to prevent harm.',
  },
  {
    id: 9,
    question: 'What is the role of human oversight in ensuring AI reliability under Australian guidelines?',
    options: [
      'Human oversight is not necessary',
      'Appropriate human oversight to monitor and intervene when needed',
      'Only automated oversight is required',
      'Human oversight is only for government AI',
    ],
    correctAnswer: 1,
    explanation: 'Australian guidelines emphasize appropriate human oversight to monitor AI system performance and enable human intervention when systems behave unexpectedly or cause harm.',
  },
  {
    id: 10,
    question: 'How should organizations address AI system security under Australian AI ethics?',
    options: [
      'Security is separate from ethics',
      'Security is integral to reliability and safety, requiring appropriate protections',
      'Only government AI needs security',
      'Security is optional',
    ],
    correctAnswer: 1,
    explanation: 'Security is considered integral to AI reliability and safety under Australian guidelines, requiring organizations to implement appropriate protections against unauthorized access and manipulation.',
  },
];
